{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Author: Lauren Blakeley\")\n",
    "print(\"\\nPredicting Lung Cancer Using Primarily Binary Variables\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Import Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
    "from xgboost import XGBClassifier\n",
    "import itertools\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "\n",
    "##Read in Data\n",
    "df = pd.read_csv('C:/Users/Lauren/OneDrive/DSC_478/Final_Project/lung_cancer_dataset.csv')\n",
    "\n",
    "##Check first few rows\n",
    "print(df.head())\n",
    "\n",
    "##Check for null values \n",
    "print(df.isnull().sum())\n",
    "##There are no null values in any of the columns\n",
    "\n",
    "##Check data types of variables\n",
    "print(df.dtypes)\n",
    "##Only two fields are not of data type int64, gender and lung_cancer. They are of type object. Gender has the values 'M' and 'F' to represent male and female. Lung_cancer has \n",
    "# values 'YES' and 'NO' to represent the existence or absence of lung cancer. \n",
    "\n",
    "##Check the number of unique values in each field\n",
    "print(df.nunique())\n",
    "##Out of the 15 idependent (explanatory) variables, only 1 (Age) had more than 2 unique values. This makes sense as every other variable is binary with 1 (absence of symptom) \n",
    "# or 2 (presence of symptom).\n",
    "\n",
    "##Review the general statistics for the different variables\n",
    "print( df.describe())\n",
    "##Most variables are binary with 1 or 2 being the only value options, but interestingly enough the average for these binary variables, the average (mean score) for all symtoms\n",
    "# was very close to, if not 1.5, which indicates the representation of the symptoms per observation is split about 50/50 in the data. This indicates a possibility that\n",
    "# while certain symptoms may be better at indicating whether a person actually has lung cancer or not, a specific combination of present symptoms may actually be more powerful.\n",
    "# This observation supports the logic that, in the case of most diagnostic efforts, it is the constitution of symptoms that lead to a diagnosis, rather than the isolated presence\n",
    "# of one given symptom.\n",
    "\n",
    "\n",
    "##Creating histograms for all numerical fields to observe distributions\n",
    "for column in df.select_dtypes(include=['number']).columns:  \n",
    "    plt.figure(figsize=(6, 4))  \n",
    "    plt.hist(df[column], bins=20, edgecolor='black')  \n",
    "    plt.title(f\"Histogram of {column}\")  \n",
    "    plt.xlabel(column)  \n",
    "    plt.ylabel(\"Frequency\") \n",
    "    plt.grid(True)  \n",
    "    plt.show()\n",
    "##I created historgrams for all numericals fields to observe how the data is distributed. Primarily, I was concerned with the field 'age' as it is the only one that is not \n",
    "# binary. The distribution of age is not normal, and appears more uniform if anything, but also there is no trend in age range. I am going to keep this in mind in case transformation\n",
    "# needs to be done on the age veriable so that it can be a potential input in building a predictive model. Also, not only is the presence vs. absence of lung cancer balanced, \n",
    "# It appears whether a symptom is present or not is also fairly equal amongst all binary features in the dataset.\n",
    "\n",
    "\n",
    "##Here I am recoding Gender so that it is binary\n",
    "df['GENDER'] = df['GENDER'].replace({'M': 0, 'F': 1})\n",
    "\n",
    "##After recoding Gender, I was concerned that the binary columns with values of 1 and 2 would allow a model to assume ordinality, so I recoded to 0 and 1 where 0 now represents \n",
    "# the absence of a symptom while 1 represents the presence of a symptom.\n",
    "binary_cols = [col for col in df.columns if col not in ['AGE', 'GENDER', 'LUNG_CANCER']]\n",
    "\n",
    "df[binary_cols] = df[binary_cols].map(lambda x: 1 if x == 2 else 0)\n",
    "\n",
    "##Now I am recoding the lung_cancer values so NO is equal to 0 (absence of) and YES is equal to 1 (presence of). I was concerned with inconsistent labelling and how that may\n",
    "# impact the ability to model the data.\n",
    "df['LUNG_CANCER'] = df['LUNG_CANCER'].map({'NO': 0, 'YES': 1})\n",
    "\n",
    "##I am printing the head of the data now to see if the changes I made were applied properly.\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " The selected features are: ['SMOKING', 'YELLOW_FINGERS', 'ANXIETY', 'PEER_PRESSURE', 'ALLERGY', 'WHEEZING', 'ALCOHOL_CONSUMING', 'COUGHING', 'SWALLOWING_DIFFICULTY', 'CHEST_PAIN']\n",
      "\n",
      "Model Performance without Interaction Terms: \n",
      "Accuracy: 0.51 \n",
      "Precision: 0.52 \n",
      "Recall: 0.55 \n",
      "AUC: 0.52\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Basic Logistic Regression Model\n",
    "\n",
    "\n",
    "##Here I am separating the features\n",
    "X = df.drop(columns=['LUNG_CANCER'])  \n",
    "y = df['LUNG_CANCER']  \n",
    "\n",
    "\n",
    "##Now I am splitting the data into train and test states, using random_state to set a seed for reproducibility. I picked 15 because it is my favorite number and inconsequential.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "\n",
    "##This line of code initializes the logistic regression model, setting max_iter to 1000 instead of the default 100 to avoid convergence warning.\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "##Now I am applying Recursive Feature Elimination (RFE) to select top 10 features, originally I did the top 5 but the accuracy, precision, and recall for the model was poor.\n",
    "rfe = RFE(estimator=logreg, n_features_to_select=10)\n",
    "X_train_rfe = rfe.fit_transform(X_train, y_train)\n",
    "X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "##Here I am getting the feature names\n",
    "selected_features = X.columns[rfe.support_].tolist()\n",
    "\n",
    "##Now I am training the logistic regression model on selected features\n",
    "logreg.fit(X_train_rfe, y_train)\n",
    "\n",
    "#Here I am making predictions\n",
    "y_pred = logreg.predict(X_test_rfe)\n",
    "\n",
    "#Now I am evaluating the model performance and storing accuracy, precision, recall, and auc results in variables.\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "auc = roc_auc_score(y_test, logreg.predict_proba(X_test_rfe)[:, 1])\n",
    "\n",
    "##Now I am displaying the results\n",
    "print( f\"\\n The selected features are: {selected_features}\")\n",
    "print(f\"\\nModel Performance without Interaction Terms: \\nAccuracy: {accuracy:.2f} \\nPrecision: {precision:.2f} \\nRecall: {recall:.2f} \\nAUC: {auc:.2f}\")\n",
    "\n",
    "##Here I am displaying a confusion matrix to visualize the correctly classified and misclassified cases.\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"No Cancer\", \"Cancer\"])\n",
    "disp.plot(cmap=\"Blues\", values_format=\"d\")  # \"Blues\" for a better visual effect\n",
    "\n",
    "plt.title(\"Confusion Matrix for Logistic Regression Model\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Interaction Features:\n",
      " Index(['AGE YELLOW_FINGERS', 'AGE PEER_PRESSURE', 'AGE CHRONIC_DISEASE',\n",
      "       'AGE FATIGUE', 'AGE WHEEZING', 'AGE ALCOHOL_CONSUMING', 'AGE COUGHING',\n",
      "       'AGE SHORTNESS_OF_BREATH', 'AGE SWALLOWING_DIFFICULTY',\n",
      "       'AGE CHEST_PAIN'],\n",
      "      dtype='object')\n",
      "\n",
      "Model Performance with Interaction Terms:\n",
      "Accuracy: 0.53, Precision: 0.52, Recall: 0.60, AUC: 0.53\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression Model with Interaction Terms\n",
    "\n",
    "##Separating features and target variables\n",
    "X = df.drop(columns=['LUNG_CANCER'])\n",
    "y = df['LUNG_CANCER']\n",
    "\n",
    "##Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "\n",
    "##Generating Interaction Terms without polynomials\n",
    "interaction = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "X_train_inter = interaction.fit_transform(X_train)\n",
    "X_test_inter = interaction.transform(X_test)\n",
    "\n",
    "##Now I am converting to a DataFrame with proper feature names\n",
    "feature_names = interaction.get_feature_names_out(X.columns)\n",
    "X_train_inter_df = pd.DataFrame(X_train_inter, columns=feature_names)\n",
    "X_test_inter_df = pd.DataFrame(X_test_inter, columns=feature_names)\n",
    "\n",
    "##Feature Selection: Select Top 10 Interaction Features using Chi-Squared\n",
    "selector = SelectKBest(score_func=chi2, k=10)\n",
    "X_train_selected = selector.fit_transform(X_train_inter_df, y_train)\n",
    "X_test_selected = selector.transform(X_test_inter_df)\n",
    "\n",
    "##Geting selected feature names\n",
    "selected_features = X_train_inter_df.columns[selector.get_support()]\n",
    "print(\"Selected Interaction Features:\\n\", selected_features)\n",
    "\n",
    "##Training logistic regression model\n",
    "logreg = LogisticRegression(max_iter=1000)\n",
    "logreg.fit(X_train_selected, y_train)\n",
    "\n",
    "##Making predictions\n",
    "y_pred_inter = logreg.predict(X_test_selected)\n",
    "\n",
    "##Evaluating performance and storing statistics in appropriately named variables\n",
    "accuracy_inter = accuracy_score(y_test, y_pred_inter)\n",
    "precision_inter = precision_score(y_test, y_pred_inter, pos_label=1)\n",
    "recall_inter = recall_score(y_test, y_pred_inter, pos_label=1)\n",
    "auc_inter = roc_auc_score(y_test, logreg.predict_proba(X_test_selected)[:, 1])\n",
    "\n",
    "# Display results\n",
    "print(f\"\\nModel Performance with Interaction Terms:\")\n",
    "print(f\"Accuracy: {accuracy_inter:.2f}, Precision: {precision_inter:.2f}, Recall: {recall_inter:.2f}, AUC: {auc_inter:.2f}\")\n",
    "\n",
    "\n",
    "##Even with including interaction terms, this logistic regression model is not- with any level of significance- better at predicting the absence or presence of lung cancer\n",
    "# based on the symptoms provided. The most significant improvement was to recall, which represents the number of true positives/ true positives + false negatives. The higher\n",
    "# the recall, the fewer the number of false negatives, which means the fewer the number of misclassified positive cases. In my opinion, if I have to pick whether accuracy, \n",
    "# precision, or recall is the best for a model that is supposed to predict the presence of lung cancer, I want to emphasize recall is the most important statistic to me overall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k (accuracy): 1\n",
      "Best k (precision): 2\n",
      "Best k (recall): 1\n",
      "KNN Model with Manhattan Distance at K = 1:\n",
      "Accuracy: 0.53\n",
      "Precision: 0.53\n",
      "Recall: 0.52\n",
      "AUC Score: 0.53\n",
      "KNN Model with Manhattan Distance at K = 2:\n",
      "Accuracy: 0.52\n",
      "Precision: 0.56\n",
      "Recall: 0.28\n",
      "AUC Score: 0.51\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'A model with higher recall (k=19) prioritizes capturing more actual lung cancer cases at the expense of misclassifying healthy individuals.\\nA model with higher precision (k=8) ensures that when it predicts lung cancer, itâ€™s more likely to be correct, but it might miss some actual cases (lower recall).\\nHow to Choose the Best k?\\nIf you want balanced performance: Choose k=8, since accuracy and precision are both optimized.\\nIf you care more about capturing all possible cancer cases (higher recall): Choose k=19 but be aware of increased false positives.\\nIf you need a compromise, consider k=10-12, which might provide a better balance.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN using Manhattan Distance \n",
    "\n",
    "##I started by testing Jaccard as, after doing research, I read it should be the best distance function when using binary variables. However, my results were very poor so I \n",
    "# decided to try Manhattan distance. I believe Manhattan yielded slightly better results because age seemed to be one of the most statistically significant predictors for\n",
    "# the presence of lung cancer and it is a binary predictor. \n",
    "\n",
    "##I am using this first section to figure out what the best K value is when performing Manhattan distance against accuracy, precision, and recall. I want to understand if \n",
    "# the same K value yields the best results for all three, or if this is not true.\n",
    "param_grid = {'n_neighbors': list(range(1, 21))}\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(metric='manhattan'), param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best k (accuracy):\", grid_search.best_params_['n_neighbors'])\n",
    "\n",
    "param_grid = {'n_neighbors': list(range(1, 21))}\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(metric='manhattan'), param_grid, cv=5, scoring='precision')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best k (precision):\", grid_search.best_params_['n_neighbors'])\n",
    "\n",
    "param_grid = {'n_neighbors': list(range(1, 21))}\n",
    "grid_search = GridSearchCV(KNeighborsClassifier(metric='manhattan'), param_grid, cv=5, scoring='recall')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best k (recall):\", grid_search.best_params_['n_neighbors'])\n",
    "\n",
    "# KNN Manhattan at K = 1\n",
    "\n",
    "##Separate features from target variable\n",
    "X = df.drop(columns=['LUNG_CANCER'])  \n",
    "y = df['LUNG_CANCER']  \n",
    "\n",
    "##Splitting data into train and test data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\n",
    "\n",
    "##Initializing and train KNN classifier with Manhattan distance @ n neighbors = 1\n",
    "knn = KNeighborsClassifier(n_neighbors=1, metric='manhattan')  \n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "##Making predictions\n",
    "y_pred = knn.predict(X_test)\n",
    "y_pred_proba = knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "##Evaluating model performance\n",
    "accuracy_1 = accuracy_score(y_test, y_pred)\n",
    "precision_1 = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall_1 = recall_score(y_test, y_pred, pos_label=1)\n",
    "auc_1 = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "##Display results\n",
    "print(f\"KNN Model with Manhattan Distance at K = 1:\")\n",
    "print(f\"Accuracy: {accuracy_1:.2f}\")\n",
    "print(f\"Precision: {precision_1:.2f}\")\n",
    "print(f\"Recall: {recall_1:.2f}\")\n",
    "print(f\"AUC Score: {auc_1:.2f}\")\n",
    "\n",
    "\"\"\"-------------------------------------------------------------------------------------------------------------------------------------------------\"\"\"\n",
    "##Separating features and target variable\n",
    "X = df.drop(columns=['LUNG_CANCER'])  \n",
    "y = df['LUNG_CANCER']  \n",
    "\n",
    "##Splitting data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\n",
    "\n",
    "##Initializing and training KNN classifier with Manhattan distance @ n neighbors = 2\n",
    "knn = KNeighborsClassifier(n_neighbors=2, metric='manhattan')  \n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "##Making predictions\n",
    "y_pred = knn.predict(X_test)\n",
    "y_pred_proba = knn.predict_proba(X_test)[:, 1]\n",
    "\n",
    "##Evaluating model performance and storing data in variables \n",
    "accuracy_2 = accuracy_score(y_test, y_pred)\n",
    "precision_2 = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall_2 = recall_score(y_test, y_pred, pos_label=1)\n",
    "auc_2 = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "##Display results\n",
    "print(f\"KNN Model with Manhattan Distance at K = 2:\")\n",
    "print(f\"Accuracy: {accuracy_2:.2f}\")\n",
    "print(f\"Precision: {precision_2:.2f}\")\n",
    "print(f\"Recall: {recall_2:.2f}\")\n",
    "print(f\"AUC Score: {auc_2:.2f}\")\n",
    "\n",
    "\n",
    "##It has been returned that a k value of 1 is best for accuracy and recall but a 2 is slightly better for precision. While accuracy is reduced by .1, to .52 when n is changed from \n",
    "#1 to 2, Recall is reduced almost in half from .52 to .28. While 1 is better, either choice of n neighbors results in a sub-par predictive model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Model:\n",
      "Accuracy: 0.53\n",
      "Precision: 0.54\n",
      "Recall: 0.52\n",
      "AUC Score: 0.54\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Model\n",
    "\n",
    "##Separating features from target variable\n",
    "X = df.drop(columns=['LUNG_CANCER'])  \n",
    "y = df['LUNG_CANCER'] \n",
    "\n",
    "##Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "\n",
    "##Initializing Random Forest model\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "##Training the model\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "##Making predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "y_pred_prob = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "##Evaluating model performance\n",
    "rf_accuracy = accuracy_score(y_test, y_pred)\n",
    "rf_precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "rf_recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "rf_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "##Display results\n",
    "print(f\"Random Forest Model:\")\n",
    "print(f\"Accuracy: {rf_accuracy:.2f}\")\n",
    "print(f\"Precision: {rf_precision:.2f}\")\n",
    "print(f\"Recall: {rf_recall:.2f}\")\n",
    "print(f\"AUC Score: {rf_auc:.2f}\")\n",
    "\n",
    "##The results of this model are all still in the .5s which is not desirable for a predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Gradient Boosting Model Performance:\n",
      "Accuracy: 0.53\n",
      "Precision: 0.53\n",
      "Recall: 0.54\n",
      "AUC Score: 0.53\n",
      "\n",
      "Best Gradient Boosting Model Performance:\n",
      "Best Parameters: {'learning_rate': 0.01, 'max_depth': 3, 'n_estimators': 50, 'subsample': 1.0}\n",
      "Accuracy: 0.4933\n",
      "Precision: 0.5015\n",
      "Recall: 0.5410\n",
      "AUC Score: 0.5076\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting Model\n",
    "\n",
    "##Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "\n",
    "##Initializing and training Gradient Boosting Classifier\n",
    "gbm = GradientBoostingClassifier(random_state=15)\n",
    "gbm.fit(X_train, y_train)\n",
    "\n",
    "##Making predictions\n",
    "y_pred = gbm.predict(X_test)\n",
    "y_pred_proba = gbm.predict_proba(X_test)[:, 1]\n",
    "\n",
    "##Evaluating model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "##Display results\n",
    "print(\"Initial Gradient Boosting Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"AUC Score: {auc:.2f}\")\n",
    "\n",
    "##The resulting statistics for my gradient boosting model have very similar values (all being .53 except for recall at .54). Again, these values are far too low for a predicitve\n",
    "# model as it appears to be a 50/50 chance as to whether the model correctly predicts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected Features (Chi-Squared): ['AGE_x_WHEEZING', 'SMOKING_x_ALLERGY', 'SMOKING_x_COUGHING', 'SMOKING_x_CHEST_PAIN', 'YELLOW_FINGERS_x_WHEEZING', 'PEER_PRESSURE_x_WHEEZING', 'PEER_PRESSURE_x_SWALLOWING_DIFFICULTY', 'ALLERGY_x_COUGHING', 'ALLERGY_x_SWALLOWING_DIFFICULTY', 'ALLERGY_x_CHEST_PAIN']\n",
      "\n",
      "XGBoost Model Performance with Chi-Squared Selected Features:\n",
      "Accuracy: 0.51\n",
      "Precision: 0.52\n",
      "Recall: 0.54\n",
      "AUC Score: 0.52\n",
      "\n",
      "XGBoost Model Performance with Interaction Terms:\n",
      "Accuracy: 0.48\n",
      "Precision: 0.49\n",
      "Recall: 0.49\n",
      "AUC Score: 0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lauren\\anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [23:22:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "C:\\Users\\Lauren\\AppData\\Local\\Temp\\ipykernel_8388\\591694006.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[feature1] * df[feature2]\n",
      "C:\\Users\\Lauren\\AppData\\Local\\Temp\\ipykernel_8388\\591694006.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[feature1] * df[feature2]\n",
      "C:\\Users\\Lauren\\AppData\\Local\\Temp\\ipykernel_8388\\591694006.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[feature1] * df[feature2]\n",
      "C:\\Users\\Lauren\\AppData\\Local\\Temp\\ipykernel_8388\\591694006.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[feature1] * df[feature2]\n",
      "C:\\Users\\Lauren\\AppData\\Local\\Temp\\ipykernel_8388\\591694006.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[feature1] * df[feature2]\n",
      "C:\\Users\\Lauren\\AppData\\Local\\Temp\\ipykernel_8388\\591694006.py:50: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[interaction_name] = df[feature1] * df[feature2]\n",
      "c:\\Users\\Lauren\\anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [23:22:40] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# XGBoost model using chi-squared and XGBoost model using interation terms\n",
    "\n",
    "\n",
    "##First I am separating features from the target variable\n",
    "X = df.drop(columns=['LUNG_CANCER'])\n",
    "y = df['LUNG_CANCER']\n",
    "\n",
    "##Now I am splitting the data into train and test data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "\n",
    "##Now I am scaling the data for chi squared using MinMax scaler to avoid negative values\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "##Now I am running the chi-squared test- looking for the features with the strongest relationship to the target variable.\n",
    "chi2_selector = SelectKBest(chi2, k=10)\n",
    "X_train_chi2 = chi2_selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_chi2 = chi2_selector.transform(X_test_scaled)\n",
    "\n",
    "##Here I am printing the features from the chi-squared test.\n",
    "selected_features = X.columns[chi2_selector.get_support()].tolist()\n",
    "print(f\"Selected Features (Chi-Squared): {selected_features}\")\n",
    "\n",
    "##Here I am training the XG Boost model\n",
    "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42)\n",
    "xgb_model.fit(X_train_chi2, y_train)\n",
    "\n",
    "##Making predictions\n",
    "y_pred = xgb_model.predict(X_test_chi2)\n",
    "y_pred_proba = xgb_model.predict_proba(X_test_chi2)[:, 1]\n",
    "\n",
    "##Evaluating model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "##Display results using Chi-Squared selected features\n",
    "print(\"\\nXGBoost Model Performance with Chi-Squared Selected Features:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"AUC Score: {auc:.2f}\")\n",
    "\n",
    "##Generating interaction terms for selected features\n",
    "interaction_terms = []\n",
    "for feature1, feature2 in itertools.combinations(selected_features, 2):\n",
    "    interaction_name = f\"{feature1}_x_{feature2}\"\n",
    "    df[interaction_name] = df[feature1] * df[feature2]\n",
    "    interaction_terms.append(interaction_name)\n",
    "\n",
    "##Preparing new dataset with interaction terms\n",
    "X_interact = df[selected_features + interaction_terms]\n",
    "y_interact = df['LUNG_CANCER']\n",
    "\n",
    "##Splitting new dataset\n",
    "X_train_int, X_test_int, y_train_int, y_test_int = train_test_split(X_interact, y_interact, test_size=0.2, random_state=15)\n",
    "\n",
    "##Scaling interaction features\n",
    "X_train_int_scaled = scaler.fit_transform(X_train_int)\n",
    "X_test_int_scaled = scaler.transform(X_test_int)\n",
    "\n",
    "##Training XGBoost on new dataset with interaction terms\n",
    "xgb_interact_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=15)\n",
    "xgb_interact_model.fit(X_train_int_scaled, y_train_int)\n",
    "\n",
    "##Making predictions\n",
    "y_pred_int = xgb_interact_model.predict(X_test_int_scaled)\n",
    "y_pred_int_proba = xgb_interact_model.predict_proba(X_test_int_scaled)[:, 1]\n",
    "\n",
    "##Evaluating performance\n",
    "accuracy_int = accuracy_score(y_test_int, y_pred_int)\n",
    "precision_int = precision_score(y_test_int, y_pred_int)\n",
    "recall_int = recall_score(y_test_int, y_pred_int)\n",
    "auc_int = roc_auc_score(y_test_int, y_pred_int_proba)\n",
    "\n",
    "##Display results\n",
    "print(\"\\nXGBoost Model Performance with Interaction Terms:\")\n",
    "print(f\"Accuracy: {accuracy_int:.2f}\")\n",
    "print(f\"Precision: {precision_int:.2f}\")\n",
    "print(f\"Recall: {recall_int:.2f}\")\n",
    "print(f\"AUC Score: {auc_int:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Model\n",
    "\n",
    "##First I am separating the features from the target variable\n",
    "X = df.drop(columns=['LUNG_CANCER'])  \n",
    "y = df['LUNG_CANCER']  \n",
    "\n",
    "##Now I am splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15)\n",
    "\n",
    "##Initializing Bernoulli NaÃ¯ve Bayes model\n",
    "nb = BernoulliNB()\n",
    "\n",
    "##Training\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "##Making predictions\n",
    "y_pred = nb.predict(X_test)\n",
    "y_prob = nb.predict_proba(X_test)[:, 1]  # Probability estimates for ROC-AUC\n",
    "\n",
    "##Evaluating model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, pos_label=1)\n",
    "recall = recall_score(y_test, y_pred, pos_label=1)\n",
    "auc = roc_auc_score(y_test, y_prob)\n",
    "\n",
    "##Displaying results\n",
    "print(f\"NaÃ¯ve Bayes Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"AUC Score: {auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Lauren\\anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [23:48:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Lauren\\anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [23:48:52] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "c:\\Users\\Lauren\\anaconda3\\envs\\myenv\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [23:48:53] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ Stacked Ensemble Model Performance:\n",
      "Accuracy: 0.54\n",
      "Precision: 0.53\n",
      "Recall: 0.74\n",
      "AUC Score: 0.56\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Your stacked ensemble model improves recall significantly (0.7237), which is a promising sign that it is better at identifying true positive cases of lung cancer. However, accuracy and precision remain low, indicating that the model may still struggle with false positives.\\n\\nðŸ“Œ Key Observations:\\nâœ” Higher Recall (0.7237) â†’ Model is catching more actual lung cancer cases.\\nâœ” Low Precision (0.5104) â†’ Many false positives, leading to lower confidence in positive predictions.\\nâœ” Slightly Improved AUC (0.5213) â†’ Slightly better discrimination ability than random guessing.\\nâœ” Accuracy (0.5083) is still poor â†’ The model isn't generalizing well.\\n\\nðŸ“Œ What To Do Next?\\n1ï¸âƒ£ Balance Precision-Recall Tradeoff:\\n\\nIf you want higher recall, you accept more false positives (better for medical screening).\\nIf you want higher precision, you miss some positive cases but have fewer false positives.\\nTry adjusting the decision threshold (default is 0.5) to optimize F1-score.\\n2ï¸âƒ£ Hyperparameter Tuning on Base Models (XGBoost & NaÃ¯ve Bayes):\\n\\nUse GridSearchCV or RandomizedSearchCV to tune hyperparameters.\\nFocus on max_depth, n_estimators, and learning_rate for XGBoost.\\nTry Laplace smoothing (var_smoothing) for NaÃ¯ve Bayes.\\n3ï¸âƒ£ Feature Engineering:\\n\\nConsider dropping low-importance features using SHAP values.\\nCreate more interaction terms based on domain knowledge.\\nCheck for collinearity (highly correlated features).\\n4ï¸âƒ£ Try a Different Meta-Learner:\\n\\nInstead of logistic regression, try XGBoost as the final estimator in the stack.\\nfinal_estimator=XGBClassifier(n_estimators=50, learning_rate=0.1)\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensemble model\n",
    "\n",
    "##First, separate features from target variable\n",
    "X = df.drop(columns=['LUNG_CANCER'])\n",
    "y = df['LUNG_CANCER']\n",
    "\n",
    "##Next, I'm splitting the data into train and test data sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=15, stratify=y)\n",
    "\n",
    "#Now, I'm standardizing the data (for NaÃ¯ve Bayes)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "##Here I'm defining the Base models (XGBoost and Naive Bayes)\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=15)\n",
    "nb = GaussianNB()\n",
    "\n",
    "##Defining the Stacking Model (Meta-Learner is Logistic Regression)\n",
    "stacked_model = StackingClassifier(\n",
    "    estimators=[('xgb', xgb), ('nb', nb)],  \n",
    "    final_estimator=LogisticRegression(), \n",
    "    stack_method='predict_proba' \n",
    ")\n",
    "\n",
    "##Training Stacking Model\n",
    "stacked_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "##Make predictions\n",
    "y_pred = stacked_model.predict(X_test_scaled)\n",
    "y_pred_proba = stacked_model.predict_proba(X_test_scaled)[:, 1]  \n",
    "\n",
    "##Evaluating performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc = roc_auc_score(y_test, y_pred_proba)\n",
    "\n",
    "##Display results\n",
    "print(f\"\\nðŸ”¹ Stacked Ensemble Model Performance:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"AUC Score: {auc:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
